This is our simulator for evaluating the impact of errors in
estimating the size when performing size-based scheduling in big-data
workloads. Details in our technical report, available at 
http://arxiv.org/abs/1306.6023.

Needed software:
 - wget (to get the datasets)
 - Python 3.2 or 2.7
 - Python libraries: numpy, matplotlib (for plots), blist

Pay attention: blist v1.3.4 has a trivial bug (a couple of missing
underscores) that makes it not work in Python 3.2. At the time of this
writing, the problem is fixed on github, but not on the version that
can be installed from pypi. If you want to manually fix the bug, it's
sufficient to replace self._mapping.sortedkeys with
self._mapping._sortedkeys in lines 32 and 53 of _sorteddict.py.

I got reported that this appears not to be sufficient with the Py2.7
installed by default on MacOS. Contact me with your error if you have
this problem.

=== GET THE WORKLOADS ===

$./get_datasets
(will get the workloads from the SWIM git repository)

=== RUN THE EXPERIMENT ===

usage: ./experiment.py -h

This will compute the sojourn times for each of the jobs in the
specified TSV file using FIFO, PS, SRPT and two variants of FSP that
cope with errors (described again in our technical report). When
performing experiments, it will print the mean sojourn times for each
instance of the experiments. Since FIFO and PS do not suffer from
estimation errors and they only depend on the trace, they will be
computed only once rather than repeated depending on the number of
iterations.

Results will be output in a binary file (Python's shelve format) named
'results_FILENAME[.tsv stripped]_SIGMA_D-OVER-N_LOAD.s'. If such a
file already exists, we simply add the results of more experiment runs
to it if the number of existing runs is not enough.

=== PLOT THE RESULTS ===

usage: plot_sojourn_vs_error.py -h
usage: plot_sojourn_vs_load.py -h
usage: plot_sojourn_vs_dn.py -h

=== REPEAT THE EXPERIMENTS AND PERFORM THE PLOTS IN THE TECHNICAL REPORT ===

$./do_experiments
$./do_plots